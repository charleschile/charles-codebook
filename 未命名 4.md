we, you know the whole idea right? You will be having some documents in S. 3. And then you have to create embedding. And then, yeah, you have to chunk the data, and then you have to create embedding on those channels and then store it in index table. And then like that table would be useful. Very.



chunk 


---



create hidden sql table in the back end


So that's that's what I am saying. So right now we don't have the so, for we can allow users to upload the document. But in order for us to specify the document. URL, right?


sql包->sql engine-> logical plan

compile -> physical plan



database -> query plan > logical plan -> physical plan -> execution plan


build.go:
 package which contains all the keywords like insert select Update delete and all those things. So if you look at this, these are actually parser keywords.

`buildCreateIndex`
build index will create index comprises of unique Index Regular Secondary Index vector Index and Master Index logics.

build unique indexes
```go
if uIdx != nil {
		if err := buildUniqueIndexTable(indexInfo, []*tree.UniqueIndex{uIdx}, colMap, oriPriKeyName, ctx); err != nil {
			return nil, err
		}
		createIndex.TableExist = true
	}
```


build secondary index:
```go
if sIdx != nil {
		if err := buildSecondaryIndexDef(indexInfo, []*tree.Index{sIdx}, colMap, oriPriKeyName, ctx); err != nil {
			return nil, err
		}
		createIndex.TableExist = true
	}
```

secondary index comprises of regular secondary index, vector index, master index

---





llm也是secondary index
So all the new new indexes also will be part of secondary index, which is the Llm index that you're working on.

 I'm also working on a separate index called the Full Text Index, which I'll be adding to this thing as well.


`buildSecondaryIndexDef`:you have the regular secondary index which you will be building index dev.
And then this is the part where you will be building. Ivf flat index which is the vector, index.


---

`buildIvfFlatSecondaryIndexDef`

so in the case of Ivf or vector index, we have to create 3 tables 3 hidden tables which will be part of the index. So I am creating details for meta table centroid and entries table. 

```
在向量索引（Vector Index）中，为了实现高效的向量相似性搜索，通常需要创建三个隐藏表，这些表在索引的内部结构中起着关键作用。具体来说，这些表包括：

Meta Table (元数据表)：

功能：存储索引的元数据，如索引的配置信息、参数和状态等。
内容：可能包括索引创建时间、参数设置（如向量维度、分区数量）、索引的版本信息和其他与索引相关的元数据。
Centroid Table (质心表)：

功能：存储向量分区的质心（centroids）信息。质心是向量聚类算法（如K-means算法）生成的代表各个簇中心的向量。
内容：每个质心对应一个簇，表中记录了这些质心向量及其相关信息，如质心的ID、向量值和可能的其他统计数据。
Entries Table (条目表)：

功能：存储实际的数据向量及其与质心的关系。每个数据向量会被分配到离它最近的质心，从而形成簇。
内容：包括每个向量的ID、向量值以及它所属的质心ID。这使得在查询时可以快速找到与查询向量最相似的簇，从而加速相似性搜索。
通过这三个表的配合，向量索引能够实现以下功能：

快速聚类：质心表（Centroid Table）允许快速确定查询向量应归属的簇，从而减少需要比较的向量数量。
高效搜索：条目表（Entries Table）保存了实际的数据向量，查询时只需要比较特定簇中的向量，提升了搜索效率。
元数据管理：元数据表（Meta Table）提供了索引的配置信息和状态管理，方便对索引进行维护和优化。
通过这种结构，向量索引能够在处理大规模数据集时保持高效的相似性搜索性能。
```





The overall idea is that you'll be defining the table schema. And this thing. So for our case the table, the index hidden table would look something like this.

```go
		// 1.d PK def
		tableDefs[0].Pkey = &PrimaryKeyDef{
			Names:       []string{catalog.SystemSI_IVFFLAT_TblCol_Metadata_key},
			PkeyColName: catalog.SystemSI_IVFFLAT_TblCol_Metadata_key,
		}
```

original_table_primary key
chunk
embedding



So the corresponding embedding for the chat. So you will be doing schema definition something like this. 

This will be probably just one table for the Llm index rather than 3 tables for vector, index. So yeah, you'll be just needing to create one table.




---
重要
meta主要是对于vector来说的，我们不需要创建meta数据这个表格
对于vector来说，metadata table is basically storing information related to what is the current version of centroid that we need to use


对于`buildIvfFlatSecondaryIndexDef`

this is the part where we define the stable schema this is the index definition for the Iv flat secondary index. You will need to create a similar function which creates the index definition.


complie中compile.go中有createindex
```go
	case CreateIndex:
		return s.CreateIndex(c)
```

点进去
```go
if indexDef.Unique {
			// 1. Unique Index related logic
			err = s.handleUniqueIndexTable(c, indexDef, qry.Database, originalTableDef, indexInfo)
		} else if !indexDef.Unique && catalog.IsRegularIndexAlgo(indexAlgo) {
			// 2. Regular Secondary index
			err = s.handleRegularSecondaryIndexTable(c, indexDef, qry.Database, originalTableDef, indexInfo)
		} else if !indexDef.Unique && catalog.IsMasterIndexAlgo(indexAlgo) {
			// 3. Master index
			err = s.handleMasterIndexTable(c, indexDef, qry.Database, originalTableDef, indexInfo)
		} else if !indexDef.Unique && catalog.IsIvfIndexAlgo(indexAlgo) {
			// 4. IVF indexDefs are aggregated and handled later
			if _, ok := multiTableIndexes[indexDef.IndexName]; !ok {
				multiTableIndexes[indexDef.IndexName] = &MultiTableIndex{
					IndexAlgo: catalog.ToLower(indexDef.IndexAlgo),
					IndexDefs: make(map[string]*plan.IndexDef),
				}
			}
			multiTableIndexes[indexDef.IndexName].IndexDefs[catalog.ToLower(indexDef.IndexAlgoTableType)] = indexDef
		}
```

以regular为例，点进去她有一个table是b tree
而我们是llm


we had to create a map and then handle it separately in that particular function.



`handleVectorIvfFlatIndex`


`genCreateIndexTableSqlForIvfIndex`



So the population logic is different for your scenario in the in your scenario. You'll be reading  the column, then, doing the chunking, then doing the embedding, and then finally writing it as insert statements.
`handleIvfIndexMetaTable`



But master index seems good start for them as well.




其中一个启动mo:
```shell
./mo-service -debug-http :9876 -launch ./etc/launch/launch.toml >out.log 2>err.log
```



![[截屏2024-07-10 16.59.07.png]]


在开一个terminal启动
```shell
mysql -h 127.0.0.1 -P 6001 -udump -p111
```


```sql
create database if not exists a;

use a;

CREATE TABLE `t5` (
    `a` INT NOT NULL,
    `b` VECF32(960) DEFAULT NULL,
    PRIMARY KEY (`a`),
    KEY `idx5` USING ivfflat (`b`) lists = 500 op_type 'vector_l2_ops'
);

CREATE TABLE `t7` (
    `a` INT NOT NULL,
    `b` VECF32(3) DEFAULT NULL,
    PRIMARY KEY (`a`),
    KEY `idx7` USING ivfflat (`b`) lists = 2 op_type 'vector_l2_ops'
);

insert into `t7` (`a`,`b`) values(1, '[1.1, 1.2, 3.1]');


show create table t5;

select * from mo_catalog.mo_indexes where name="idx5";

 select * from  `__mo_index_secondary_01909be9-f06b-758d-b7a4-7ed6e82eefeb`;
 
mysql> select * from `__mo_index_secondary_01909be9-f06b-75cc-b02f-9247a2ce34a0` limit 1;


```


```
we have created the table with 2 columns, A and B
and then we have primary key on a and then secondary key on b
the secondary key name is idx5


you will see that there are 3 records in the
mo indexes of mo catalog database. So mo indexes is the table name, and then mo catalog is the database name 


mo catalog is an internal database as in it's specific to metrics, origin and such. Okay, if you look at MYSQL, there is information, schema database which stores all the necessary metadata for the particular MYSQL tables right?
  
```


```
创建表 t5：这条语句创建一个名为 t5 的表。

定义列 a：

a 是一个整数类型 (INT)。
该列不能为空 (NOT NULL)。
该列是主键 (PRIMARY KEY)，意味着每行在这列上的值必须唯一且不能为空。
定义列 b：

b 是一个自定义类型 VECF32，长度为960。这通常用于表示一个包含960个浮点数的向量。
该列可以为空 (DEFAULT NULL)，即插入记录时可以不为此列赋值。
定义索引 idx5：

为列 b 创建了一个名为 idx5 的索引。
使用 ivfflat 索引类型，这是一个常用于向量数据的索引类型。
参数 lists = 500 表示创建索引时使用500个列表。
参数 op_type = 'vector_l2_ops' 指定了向量操作类型为L2距离计算，即欧氏距离。
这个表 t5 主要用于存储带有整数主键 a 和浮点数向量 b 的数据，并且为向量列 b 创建了一个高效的向量检索索引。这在机器学习和数据科学中非常常见，尤其是用于快速查找和检索相似向量的应用场景。
```



---
 attach debugger to process

使用ide可以在`run`里面选择`attach to process`



When I started off with vector index, I had, I had to go through similar process, where, like, I have to add to kind of see other Pr request which was for secondary index or unique index, and then,
make similar changes and then see my change. My code was entering that path, and then


incorporate all the other functions. Like, basically, we have to support insert function update function, delete function.


Yeah, we have to add a new function, and then support querying from that particular thing.



---
creating the particular table. Right? Once you create the table, make sure to create the vector, index on that table.
So here, when you create a particular hidden table which is original table and embedding right?
you have to create an vector. Index on this embedding column so that it can be easily queried, or something of that sort. So


---



And the output can be Json.


So once you pass the model name as an argument to the create index. We will be using the model name, and then basically mapping corresponding dimension length. And that will be used for creating the underlying tables. 



now coming to the index hidden table part. So there is original table primary key, which is the primary key of the original table.

So it is kind of used as a mapping.
We might need to modify this table structure. Think of any better structure like, think of primary keys to use for this table structure. Think of secondary key would be definitely embedding. So there is definitely no doubt in that.



lvf flat index is basically a centroid based index It creates 100 centroids. And then maps. All the entries. Based on L, 2 distance to the centroid. So that is how current vector, index is supported in metrics. Origin.


So this would be the syntax. Okay, create Llm index. Idx on table text

But the role idea is that you create an Llm. Index and then pass 3 parameters, list 100 opt type L. 2. And then embedding model as an argument, and then that should create this particular table and then create an index on that.




create index would have a dependency on this chunk and embedding. But you can start working on it and then create the background table and all those things right that you that I just mentioned make sure that need not be the embedding and all those things. But yeah, at least you have something working. And once the once they have the functions ready, you can start working on integrating them.




---

















flexible







































